需要加个队列，把分析文本之后需要进行下载的url 放到队列里面

对于一个文本分析出来的要下载的url？是否要加个事务id？ 把一个事务进行一致性处理，比如失败了，就回滚整个事务？

定时 启动 抓取

多线程

考虑并发容器 如并发hashmap

downloader  应该写成单例模式
------------------
对于配置的url，如果不指定downloader，那就默认为html
---------------------
downloader 使用枚举
spider  使用注解
---------------
queue
分析完html 之后吧pic  或者 viedeo的链接 扔进队列
-----------------------------
启动crawler之后，使用线程池。
------------------------------
classloader  、 以及jar包的加载


---------------------------------------------------------
读取配置

---------------------

线程池

